{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# DATASET IMPORT\n",
    "\n",
    "# Load dataLinux: 10k builds from Linux Testers containing flaky runs and failure runs\n",
    "dataLinux = pd.read_json('dataset.35past.Linux10k.json')\n",
    "\n",
    "# Load dataPass: 2 builds from Linux Testers containing flaky runs, failure runs but more importantly all pass runs\n",
    "dataPass = pd.read_json('dataset.pass.json')\n",
    "\n",
    "# Load nft: List of Passing tests that are never found to be flaky or legit elsewhere\n",
    "file121= open('nft-121.json')\n",
    "file123= open('nft-123.json')\n",
    "nft121 = json.load(file121)\n",
    "nft123 = json.load(file123)\n",
    "file121.close()\n",
    "file123.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: Counter({0: 1482476, 2: 306017, 1: 11643})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-343-860cb8411a6e>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataTrain[\"label\"] = dataTrain[\"label\"].map({0:1, 1:0, 2:0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Train: Counter({1: 1264973, 0: 187077})\n",
      "Data Test: Counter({1: 217503, 0: 2320})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Get data about PASS (2), LEGIT (1) and FLAKY (0) run\n",
    "dataPass = dataPass[(dataPass[\"label\"] == 2) & (dataPass[\"testSource\"] != \"\")]\n",
    "dataFlaky = dataLinux[(dataLinux[\"label\"] == 0) & (dataLinux[\"testSource\"] != \"\")]\n",
    "dataLegit = dataLinux[(dataLinux[\"label\"] == 1) & (dataLinux[\"testSource\"] != \"\")]\n",
    "\n",
    "# Keep clean NFT\n",
    "dataPass121 = dataPass[(dataPass[\"buildId\"] == 121238) & (dataPass[\"testId\"].isin(nft121))]\n",
    "dataPass123 = dataPass[(dataPass[\"buildId\"] == 123038) & (dataPass[\"testId\"].isin(nft123))]\n",
    "dataPasses = pd.concat([dataPass121, dataPass123])\n",
    "\n",
    "# Building one set of pass legit and flaky\n",
    "data = pd.concat([dataPasses, dataFlaky, dataLegit])\n",
    "data[\"flakeRate\"] = data[\"flakeRate\"].fillna(0)\n",
    "print(\"Data:\", Counter(data[\"label\"]))\n",
    "\n",
    "# Split 80/20\n",
    "dataTrain = data[data[\"buildId\"] <= 121238]\n",
    "dataTest = data[(data[\"buildId\"] > 121238) & (data[\"buildId\"] <= 123038)]\n",
    "\n",
    "\n",
    "# TRAINING SET (Uncomment the RQ to check, comment the others)\n",
    "# RQ 1\n",
    "dataTrain = dataTrain.drop_duplicates(subset=[\"testSource\", \"label\"], keep='first')\n",
    "dataTrain[\"label\"] = dataTrain[\"label\"].map({0:1, 1:0, 2:0})\n",
    "\n",
    "# RQ 2\n",
    "# dataTrain[\"label\"] = dataTrain[\"label\"].map({0:1, 1:0, 2:0})\n",
    "\n",
    "# RQ 3\n",
    "# dataTrain[\"label\"] = dataTrain[\"label\"].map({0:1, 1:0, 2:0})\n",
    "\n",
    "\n",
    "# TEST SET\n",
    "dataTest = dataTest[(dataTest[\"label\"] == 1) | (dataTest[\"label\"] == 0)]\n",
    "# Adapt labels: Flaky == 1, Legit == 0\n",
    "dataTest[\"label\"] = dataTest[\"label\"].map({0:1, 1:0})\n",
    "\n",
    "print(\"Data Train:\", Counter(dataTrain[\"label\"]))\n",
    "print(\"Data Test:\", Counter(dataTest[\"label\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "Counter({1: 1264973, 0: 187077})\n",
      "Test set:\n",
      "Counter({1: 217503, 0: 2320})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer, Binarizer\n",
    "\n",
    "# Columns definition\n",
    "testSource_col = \"testSource\"\n",
    "cat_cols = [\"testSuite\"]\n",
    "std_cols = [\"flakeRate\"]\n",
    "other_cols = [\"runDuration\"]\n",
    "\n",
    "# Feature transformation (Uncomment the RQ to check, comment the others)\n",
    "# RQ1 or RQ2 \n",
    "cols_trans = ColumnTransformer([\n",
    "    ('testSource', CountVectorizer(max_features=100), testSource_col),\n",
    "], remainder='drop')\n",
    "\n",
    "# RQ 3 \n",
    "# cols_trans = ColumnTransformer([\n",
    "#     ('categories', OneHotEncoder(handle_unknown = \"ignore\"), cat_cols),\n",
    "#     ('testSource', CountVectorizer(max_features=100), testSource_col),\n",
    "# ], remainder='passthrough')\n",
    "\n",
    "X_train = dataTrain[other_cols + std_cols + cat_cols + [testSource_col]]\n",
    "X_test = dataTest[other_cols + std_cols + cat_cols + [testSource_col]]\n",
    "\n",
    "y_train = dataTrain[\"label\"]\n",
    "y_test = dataTest[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d70557c6-63b0-4af2-b85e-1fe29b0575f7\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"d70557c6-63b0-4af2-b85e-1fe29b0575f7\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('trans',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('categories',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['testSuite']),\n",
       "                                                 ('testSource',\n",
       "                                                  CountVectorizer(max_features=100),\n",
       "                                                  'testSource')])),\n",
       "                ('m',\n",
       "                 BalancedRandomForestClassifier(n_estimators=200, n_jobs=14,\n",
       "                                                verbose=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"dd060f45-b267-42c4-93c5-9abec46e7f32\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"dd060f45-b267-42c4-93c5-9abec46e7f32\">trans: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('categories',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 ['testSuite']),\n",
       "                                ('testSource',\n",
       "                                 CountVectorizer(max_features=100),\n",
       "                                 'testSource')])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b8299e6b-cf56-4ca3-aa03-11b675a82790\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b8299e6b-cf56-4ca3-aa03-11b675a82790\">categories</label><div class=\"sk-toggleable__content\"><pre>['testSuite']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ba1fcc39-6d22-494e-91e9-cd6427e73bdf\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"ba1fcc39-6d22-494e-91e9-cd6427e73bdf\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1f3b2daf-4742-483f-9fd8-83c669dcecc4\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"1f3b2daf-4742-483f-9fd8-83c669dcecc4\">testSource</label><div class=\"sk-toggleable__content\"><pre>testSource</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7439d765-1511-4ee3-9860-f4fe70682287\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"7439d765-1511-4ee3-9860-f4fe70682287\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_features=100)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4584cedd-4497-40c2-b096-9f4757681cd8\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"4584cedd-4497-40c2-b096-9f4757681cd8\">BalancedRandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>BalancedRandomForestClassifier(n_estimators=200, n_jobs=14, verbose=1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('trans',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('categories',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['testSuite']),\n",
       "                                                 ('testSource',\n",
       "                                                  CountVectorizer(max_features=100),\n",
       "                                                  'testSource')])),\n",
       "                ('m',\n",
       "                 BalancedRandomForestClassifier(n_estimators=200, n_jobs=14,\n",
       "                                                verbose=1))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NORMAL PIPELINE\n",
    "from numpy import mean\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, r2_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Pipeline\n",
    "smote = SMOTE(sampling_strategy=0.4)\n",
    "featureSelection = SelectKBest(chi2, k=60)\n",
    "rfc = BalancedRandomForestClassifier(n_estimators=200, n_jobs=14, verbose=1)\n",
    "\n",
    "steps = [\n",
    "    ('trans', cols_trans),\n",
    "#     ('fs', featureSelection),\n",
    "    ('s', smote), \n",
    "    ('m', rfc)\n",
    "]\n",
    "pipe = Pipeline(steps=steps)\n",
    "display(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend ThreadingBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done  22 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=14)]: Done 172 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=14)]: Done 200 out of 200 | elapsed: 11.6min finished\n",
      "[Parallel(n_jobs=14)]: Using backend ThreadingBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done  22 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=14)]: Done 172 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=14)]: Done 200 out of 200 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision 0.9954188542489429\n",
      "Recall 0.9850162986257661\n",
      "MCC 0.40010839105685064\n",
      "F1 0.9901902558852688\n",
      "R2 -0.8492583514900396\n"
     ]
    }
   ],
   "source": [
    "# Fit and test\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Scores\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nPrecision\", precision)\n",
    "print(\"Recall\", recall)\n",
    "print(\"MCC\", mcc)\n",
    "print(\"F1\", f1)\n",
    "print(\"R2\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion matrix\n",
    "metrics.plot_confusion_matrix(pipe, X_test, y_test, normalize=None, cmap='Blues', \n",
    "                              display_labels=[\"Non-Flaky\", \"Flaky\"], values_format = '.0f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Information about false positives\n",
    "fp = np.logical_and(y_test != y_pred, y_pred == 1)\n",
    "tn = np.logical_and(y_test == y_pred, y_test == 0)\n",
    "X_fp = X_test[fp]\n",
    "X_tn = X_test[tn]\n",
    "data_fp = dataTest.loc[X_fp.index]\n",
    "data_fp_fr0 = data_fp[data_fp[\"flakeRate\"] > 0]\n",
    "\n",
    "print(\"Number of FP:\", len(X_fp))\n",
    "print(\"Number of FP:\", len(X_tn))\n",
    "print(\"Number of FP with flake Rate > 0:\", len(data_fp_fr0))\n",
    "print(\"FPR:\", len(X_fp) / (len(X_fp) + len(X_tn)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
